{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5940ae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2597e008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 1 classes.\n",
      "Found 0 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255)\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_dir = os.path.join('MNIST_FILE')\n",
    "val_dir = os.path.join('MNIST_FILE/')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, batch_size=16, target_size=(224, 224), color_mode='rgb')\n",
    "val_generator = val_datagen.flow_from_directory(val_dir, batch_size=16, target_size=(224, 224), color_mode='rgb')\n",
    "\n",
    "# number of classes\n",
    "K = 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f95a45d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Inputs to a layer should be tensors. Got: <tensorflow.python.keras.layers.core.Activation object at 0x00000296106EBA90>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-7807a0220953>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv2_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv3_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv4_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv5_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-7807a0220953>\u001b[0m in \u001b[0;36mconv4_layer\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    996\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 998\u001b[1;33m       \u001b[0minput_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    999\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1000\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;31m# have a `shape` attribute.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Inputs to a layer should be tensors. Got: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Inputs to a layer should be tensors. Got: <tensorflow.python.keras.layers.core.Activation object at 0x00000296106EBA90>"
     ]
    }
   ],
   "source": [
    "input_data = tf.keras.Input(shape=(224, 224, 3), dtype='float32', name='input')  # 224*224로 샘플링, 채널3\n",
    "\n",
    "def conv1_layer(x):\n",
    "    x = tf.keras.layers.ZeroPadding2D(padding = (3,3))(x)  # 이미지 사이즈 맞추기\n",
    "    x = tf.keras.layers.Conv2D(64, (7, 7), strides=(2,2))(x)  # 입력값, 7*7,64,stride=2\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.ZeroPadding2D(padding=(1,1))(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv2_layer(x):\n",
    "    x = tf.keras.layers.MaxPooling2D((3, 3), 2)(x)  # maxpooling 3*3, stride=2\n",
    "\n",
    "    shortcut = x\n",
    "\n",
    "    for i in range(3):\n",
    "        if i == 0:  # 이전 stage에서 가져온 텐서의 dimension을 증가 시켜야 함\n",
    "            x = tf.keras.layers.Conv2D(64, (1, 1))(x)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)  # 배치 정규화\n",
    "            x = tf.keras.layers.Activation('relu')(x)  # relu\n",
    "\n",
    "            x = tf.keras.layers.Conv2D(64, (3, 3), padding='same')(x)  # 3*3 필터 사용할 때 padding = same\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "            x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "            x = tf.keras.layers.Conv2D(256, (1, 1))(x)\n",
    "            shortcut = tf.keras.layers.Conv2D(256, (1, 1))(shortcut)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "            shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
    "\n",
    "            x = tf.keras.layers.Add()([x, shortcut])    # 더해주기\n",
    "            x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "            shortcut = x\n",
    "        else:\n",
    "            x = tf.keras.layers.Conv2D(64, (1, 1))(x)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "            x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "            x = tf.keras.layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "            x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "            x = tf.keras.layers.Conv2D(256, (1, 1))(x)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "            x = tf.keras.layers.Add()([x, shortcut])\n",
    "            x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "            shortcut = x\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv3_layer(x):\n",
    "    shortcut = x\n",
    "\n",
    "    for i in range(4):\n",
    "        if i == 0:          # 이전 stage에서 가져온 텐서의 dimension을 증가 시켜야 함\n",
    "            x = tf.keras.layers.Conv2D(128, (1, 1), strides=(2,2))(x)  # 논문 3.3 1*1 convolutions 는 stride2\n",
    "            x = tf.keras.layers.BatchNormalization()(x)                #배치\n",
    "            x = tf.keras.layers.Activation('relu')(x)                  #\n",
    "\n",
    "            x = tf.keras.layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "            x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "            x = tf.keras.layers.Conv2D(512, (1, 1))(x)  # input 의 차원이 1x1 convolution과 stride=2에 의해 바뀌게 된다.\n",
    "            shortcut = tf.keras.layers.Conv2D(512, (1, 1), strides=(2,2))(shortcut)  # 그러므로 skip connection도 차원 변화를 처리해줘야 한다.\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "            shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
    "\n",
    "            x = tf.keras.layers.Add()([x, shortcut])   #residual connection\n",
    "            x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "            shortcut = x\n",
    "        else:\n",
    "            x = tf.keras.layers.Conv2D(128, (1, 1))(x)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "            x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "            x = tf.keras.layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "            x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "            x = tf.keras.layers.Conv2D(512, (1, 1))(x)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "            x = tf.keras.layers.Add()([x, shortcut])\n",
    "            x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "            shortcut = x\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv4_layer(x):\n",
    "    shortcut = x\n",
    "\n",
    "    for i in range(6):\n",
    "        if i == 0:\n",
    "            x = tf.keras.layers.Conv2D(256, (1, 1), strides=(2,2))(x)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "            x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "            x = tf.keras.layers.Conv2D(256, (3, 3), padding='same')(x)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "            x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "            x = tf.keras.layers.Conv2D(1024, (1, 1))(x)\n",
    "            shortcut = tf.keras.layers.Conv2D(1024, (1, 1), strides=(2,2))(shortcut)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "            shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
    "\n",
    "            x = tf.keras.layers.Add()([x, shortcut])\n",
    "            x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "            shortcut = x\n",
    "\n",
    "        else:\n",
    "            x = tf.keras.layers.Conv2D(256, (1, 1))(x)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "            x = tf.keras.layers.Activation('relu')\n",
    "\n",
    "            x = tf.keras.layers.Conv2D(256, (3, 3), padding='same')(x)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "            x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "            x = tf.keras.layers.Conv2D(1024, (1, 1))(x)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "            x = tf.keras.layers.Add()([x, shortcut])\n",
    "            x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "            shortcut = x\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv5_layer(x):\n",
    "    shortcut = x\n",
    "\n",
    "    for i in range(3):\n",
    "        if i == 0:\n",
    "            x = tf.keras.layers.Conv2D(512, (1, 1), strides=(2,2))(x)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "            x = tf.keras.layers.Activation('relu')\n",
    "\n",
    "            x = tf.keras.layers.Conv2D(512, (3, 3), padding='same')(x)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "            x = tf.keras.layers.Activation('relu')\n",
    "\n",
    "            x = tf.keras.layers.Conv2D(2048, (1, 1))(x)\n",
    "            shortcut = tf.keras.layers.Conv2D(2048, (1, 1), strides=(2,2))(shortcut)\n",
    "            x = tf.keras.layers.BatchNormalization(x)\n",
    "            shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
    "\n",
    "            x = tf.keras.layers.Add()([x, shortcut])\n",
    "            x = tf.keras.layers.Activation('relu')\n",
    "\n",
    "            shortcut = x\n",
    "        else:\n",
    "            x = tf.keras.layers.Conv2D(512, (1, 1))(x)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "            x = tf.keras.layers.Activation('relu')\n",
    "\n",
    "            x = tf.keras.layers.Conv2D(512, (3, 3), padding='same')\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "            x = tf.keras.layers.Activation('relu')\n",
    "\n",
    "            x = tf.keras.layers.Conv2D(2048, (1, 1), strides=(1,1))(x)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "            x = tf.keras.layers.Add()([x, shortcut])\n",
    "            x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "            shortcut = x\n",
    "    return x\n",
    "\n",
    "\n",
    "x = conv1_layer(input_data)\n",
    "x = conv2_layer(x)\n",
    "x = conv3_layer(x)\n",
    "x = conv4_layer(x)\n",
    "x = conv5_layer(x)\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "output_tensor = tf.keras.layers.Dense(K, activation='softmax')(x)\n",
    "\n",
    "resnet50 = tf.keras.Model(input_data, output_tensor)\n",
    "resnet50.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
